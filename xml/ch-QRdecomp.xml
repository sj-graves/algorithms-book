<chapter xmlns:xi="http://www.w3.org/2001/XInclude" xml:id="ch-QRdecomp" >
    <title>Matrix decomposition: QR decomposition</title>


    <objectives>
        <ol type="1">
            <li><p>Discuss least squares regression</p></li>
            <li><p>Discuss the Gram-Schmidt orthonormalization algorithm</p></li>
            <li><p>Discuss <m>QR</m> decomposition using Householder reflectors</p></li>
        </ol>
    </objectives>
    <introduction>
        <p>
            In this chapter, we will unite two mathematical problems which seem, on the surface, to be totally unrelated: curve fitting via least squares regression and production of an orthogonal factorization of a matrix.
        </p>
        <definition>
            <title>Orthogonal matrices</title>
            <statement>
                A matrix <m>Q</m> is <term>orthogonal</term> if and only if <m>Q^T=Q^{-1}.</m> An <term>orthognal factorization</term> of a matrix <m>A</m> is a factorization <m>A=QR</m> where the matrix <m>Q</m> is orthogonal.
            </statement>
        </definition>
    </introduction>
    <xi:include  href="sec-QRdecomp-leastsquares.xml" />
    <xi:include  href="sec-QRdecomp-bestfit.xml" />
    <xi:include  href="sec-QRdecomp-gramschmidt.xml" />
    <xi:include  href="sec-QRdecomp-QRdecomp.xml" />
    <xi:include  href="sec-QRdecomp-householder.xml" />
</chapter>
